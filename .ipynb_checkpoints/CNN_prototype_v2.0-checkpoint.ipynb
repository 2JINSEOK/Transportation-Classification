{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "322075d1",
   "metadata": {},
   "source": [
    "# 20220125 (Tue)\n",
    "\n",
    "- shuffle (pandas -> numpy -> dataset.shuffle()) (*)\n",
    "- A, B, C, D list (*)\n",
    "    - A\n",
    "        - 'light': [file.jpg ~ file.jpg] (67)\n",
    "        - 'sedan': [file.jpg ~ file.jpg] (1235)\n",
    "        - ....\n",
    "\n",
    "- target data: [light, sedan, suv, truck, van] (*)\n",
    "\n",
    "\n",
    "- simple cnn model with own data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ab1926",
   "metadata": {},
   "source": [
    "- 완벽한 셔플링을 위해서는 데이터 세트의 전체 크기보다 크거나 같은 버퍼 크기가 필요\n",
    "\n",
    "- file_name = []\n",
    "\n",
    "- label = []\n",
    "- 파일 이름과 그에 대응되는 라벨 목록 필요\n",
    "\n",
    "- dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab86ccd",
   "metadata": {},
   "source": [
    "# 20220217 (Wed)\n",
    "- 학습 잘 되는지 확인해보고 acc 체크\n",
    "- 만약 acc가 낮으면 epoch 충분히 (5000)\n",
    "- epoch 충분히 되었는지 확인하기 위해서 tensorboard 사용하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8fa7881",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import LayerNormalization\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3893f5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKSPACE_PATH = os.getcwd()\n",
    "EXCEL_PATH = 'data'\n",
    "RESIZE_PATH = 'Resize'\n",
    "TRAIN_DATA_PATH = 'data' + os.sep + 'Train' + os.sep + 'Day'\n",
    "TEST_DATA_PATH = 'data' + os.sep + 'Test' + os.sep + 'Day'\n",
    "LOG_PATH = 'log'\n",
    "MODEL_PATH = 'saved_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11c4e250",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "FUNCTION NAME: image_load\n",
    "\n",
    "INPUT: dataset type (train or test)\n",
    "OUTPUT: images (list), labels (list)\n",
    "\n",
    "DATASET\n",
    "- BUS\n",
    "- Light\n",
    "- Motorcycle\n",
    "- Sedan\n",
    "- SUV\n",
    "- Truck\n",
    "- Unknown\n",
    "- Van\n",
    "\n",
    "(*) without Unknown, other datasets has same directory's structure which is Easy, Hard, Moderate\n",
    "(*) we will split the datasets between wo Unknown and Unknown\n",
    "\"\"\"\n",
    "\n",
    "def image_load(datatype, label_list):\n",
    "    path = TRAIN_DATA_PATH if (datatype == \"train\") else TEST_DATA_PATH\n",
    "    \n",
    "    images = []\n",
    "    labels = []\n",
    "    system_files = {'desktop.ini', 'whatever.ini'}\n",
    "    \n",
    "    # file_list = os.listdir(path)\n",
    "    # idx_unknown = file_list.index('Unknown')\n",
    "    \n",
    "    \n",
    "    # file_list_wo_unknown = file_list[:idx_unknown] + file_list[idx_unknown + 1:]\n",
    "    # file_list_unknown = file_list[idx_unknown]\n",
    "    \n",
    "    for label in label_list:\n",
    "        if not label == 'Unknown':\n",
    "            ###############################################################\n",
    "            # known\n",
    "            # same directory's structure which is Easy, Hard, Moderate\n",
    "            structure = os.listdir(RESIZE_PATH + os.sep + path + os.sep + label) \n",
    "    \n",
    "            for _st in structure: #  easy, moderate, hard\n",
    "                in_structure = RESIZE_PATH + os.sep + path + os.sep + label + os.sep + _st\n",
    "                file_name = list(set(os.listdir(in_structure)) - system_files)\n",
    "\n",
    "                for _file in file_name:\n",
    "                    full_name = in_structure + os.sep + _file\n",
    "                    images.append(full_name)\n",
    "\n",
    "                for i in range(len(file_name)):\n",
    "                    labels.append(label)\n",
    "        else:\n",
    "            ###############################################################\n",
    "            # unknown\n",
    "            file_name = list(set(os.listdir(RESIZE_PATH + os.sep + path + os.sep + label)) - system_files)\n",
    "            \n",
    "            for file in file_name:\n",
    "                images.append(RESIZE_PATH + os.sep + path + os.sep + label + os.sep + file)\n",
    "\n",
    "            for i in range(len(file_name)):\n",
    "                labels.append(label)\n",
    "\n",
    "        \n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78136eb9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9053\n",
      "9053\n",
      "4390\n",
      "4390\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "- BUS\n",
    "- Light\n",
    "- Motorcycle\n",
    "- Sedan\n",
    "- SUV\n",
    "- Truck\n",
    "- Unknown\n",
    "- Van\n",
    "\"\"\"\n",
    "\n",
    "label_list = ['Light', 'Sedan', 'SUV', 'Truck', 'Van']\n",
    "class_list = ['A', 'B', 'C', 'D']\n",
    "images, labels = image_load(\"train\", label_list)\n",
    "#print(images)\n",
    "\n",
    "print(len(images))\n",
    "print(len(labels))\n",
    "trainset = {'images':images, 'labels':labels}\n",
    "\n",
    "images, labels = image_load(\"test\", label_list)\n",
    "print(len(images))\n",
    "print(len(labels))\n",
    "testset = {'images':images, 'labels':labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f03920a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_by_label(dataset, target_label):  \n",
    "    dataset_returns = {'images' : [], 'labels' : []}\n",
    "    for i in range(len(dataset['labels'])):\n",
    "        if dataset['labels'][i] == target_label:\n",
    "            dataset_returns['labels'].append(dataset['labels'][i])\n",
    "            dataset_returns['images'].append(dataset['images'][i])\n",
    "    return dataset_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8394f66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_excel(dataset, datatype):\n",
    "    data = pd.DataFrame({'images' : dataset['images'], 'labels' : dataset['labels']})\n",
    "    data.to_excel(EXCEL_PATH + os.sep + datatype +'.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78a36fc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_to_excel(trainset, 'train')\n",
    "data_to_excel(testset, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d6a618e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_shuffle(dataset):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dataset['images'], dataset['labels'])) # list -> tensor\n",
    "    dataset = dataset.shuffle(buffer_size=len(dataset), seed=0)     \n",
    "    dataset_return_type = {'images' : [], 'labels' : []}\n",
    "    \n",
    "   \n",
    "    for data in list(dataset):\n",
    "        dataset_return_type['images'].append(data[0].numpy().decode())\n",
    "        dataset_return_type['labels'].append(data[1].numpy().decode())\n",
    "            \n",
    "    return dataset_return_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbf4d350",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(label): # [light .... .light, truck .... truck ]\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(label)\n",
    "    digital_label = encoder.transform(label)\n",
    "    \n",
    "    #print('type', type(digital_label))\n",
    "    \n",
    "    digital_label = digital_label.reshape(-1, 1)\n",
    "    print('digital_label', digital_label)\n",
    "    print('digital_label.shape', digital_label.shape)\n",
    "    \n",
    "    one_hot_encoder = OneHotEncoder()\n",
    "    one_hot_encoder.fit(digital_label)\n",
    "    one_hot_label = one_hot_encoder.transform(digital_label).toarray()\n",
    "    print('one_hot_label', one_hot_label.shape)\n",
    "    \n",
    "    return one_hot_label # #data x 5 (#label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54a32200",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset, validation='D'):\n",
    "    train_fname = [value for key, value in dataset.items() if key not in validation]\n",
    "    valid_fname = [dataset[validation]]\n",
    "    \n",
    "    # train_fname\n",
    "    train_labels = []\n",
    "    valid_labels = []\n",
    "    cnt = 0\n",
    "    for i in range(len(train_fname)):\n",
    "        for label in label_list:\n",
    "            for f in train_fname[i][label]['image']:\n",
    "                cnt += 1\n",
    "                img = Image.open(f, 'r')\n",
    "                img = img.resize((64, 64))\n",
    "                img = np.array(img) / 255.0\n",
    "                # (64, 64, 3)\n",
    "                \n",
    "                train_image = np.expand_dims(img, axis=0) # (1, 64, 64, 3)\n",
    "                \n",
    "                \n",
    "                if cnt == 1:\n",
    "                    train_images = train_image\n",
    "                else:\n",
    "                    train_images = np.append(train_images, train_image, axis=0) # (2, 64, 64, 3)\n",
    "                    \n",
    "                train_labels.append(label)\n",
    "                \n",
    "                \"\"\"\n",
    "                # 1 x 2 x 2 x 2\n",
    "                [\n",
    "                    [\n",
    "                       [1, 1], \n",
    "                       [2, 2]\n",
    "                    ], \n",
    "                     [\n",
    "                       [1, 1], \n",
    "                       [2, 2]\n",
    "                     \n",
    "                     \n",
    "                     ], ...\n",
    "                ]\n",
    "                \n",
    "                \"\"\"\n",
    "    # valid_fname\n",
    "    cnt = 0\n",
    "    for i in range(len(valid_fname)):\n",
    "        for label in label_list:\n",
    "            for f in valid_fname[i][label]['image']:\n",
    "                cnt += 1\n",
    "                img = Image.open(f, 'r')\n",
    "                img = img.resize((64, 64))\n",
    "                img = np.array(img) / 255.0\n",
    "                # (64, 64, 3)\n",
    "                \n",
    "                valid_image = np.expand_dims(img, axis=0) # (1, 64, 64, 3)\n",
    "                \n",
    "                \n",
    "                if cnt == 1:\n",
    "                    valid_images = valid_image\n",
    "                else:\n",
    "                    valid_images = np.append(valid_images, valid_image, axis=0) # (2, 64, 64, 3)\n",
    "                    \n",
    "                valid_labels.append(label)\n",
    "                \n",
    "    return train_images, train_labels, valid_images, valid_labels           \n",
    "                #(#data, 64, 64, 3)\n",
    "    \n",
    "    # train_fname\n",
    "    # img = Image.open(f, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0ef436b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(train_images, train_labels, test_images, test_labels):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3))) #\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(5, activation='softmax'))\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    logdir = os.path.join(LOG_PATH, datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir)\n",
    "    \n",
    "    model.fit(train_images, train_labels, epochs=30, callbacks=[tensorboard_callback])\n",
    "    model.save(MODEL_PATH)\n",
    "    test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "    \n",
    "    print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62fce83c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6789, 64, 64, 3)\n",
      "(2264, 64, 64, 3)\n",
      "digital_label [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [4]\n",
      " [4]\n",
      " [4]]\n",
      "digital_label.shape (6789, 1)\n",
      "one_hot_label (6789, 5)\n",
      "digital_label [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [4]\n",
      " [4]\n",
      " [4]]\n",
      "digital_label.shape (2264, 1)\n",
      "one_hot_label (2264, 5)\n",
      "(6789, 5)\n",
      "(2264, 5)\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 31, 31, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 29, 29, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 14, 14, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 12, 12, 64)        36928     \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 9216)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                589888    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 646,533\n",
      "Trainable params: 646,533\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "213/213 [==============================] - 3s 9ms/step - loss: 0.6936 - accuracy: 0.7465\n",
      "Epoch 2/30\n",
      "213/213 [==============================] - 2s 8ms/step - loss: 0.4597 - accuracy: 0.8362\n",
      "Epoch 3/30\n",
      "213/213 [==============================] - 2s 8ms/step - loss: 0.3689 - accuracy: 0.8665\n",
      "Epoch 4/30\n",
      "213/213 [==============================] - 2s 9ms/step - loss: 0.2931 - accuracy: 0.8948\n",
      "Epoch 5/30\n",
      "213/213 [==============================] - 2s 8ms/step - loss: 0.2317 - accuracy: 0.9184\n",
      "Epoch 6/30\n",
      "213/213 [==============================] - 2s 8ms/step - loss: 0.1684 - accuracy: 0.9396\n",
      "Epoch 7/30\n",
      "213/213 [==============================] - 2s 8ms/step - loss: 0.1270 - accuracy: 0.9576\n",
      "Epoch 8/30\n",
      "213/213 [==============================] - 2s 8ms/step - loss: 0.0707 - accuracy: 0.9763\n",
      "Epoch 9/30\n",
      "213/213 [==============================] - 2s 8ms/step - loss: 0.0511 - accuracy: 0.9838\n",
      "Epoch 10/30\n",
      "213/213 [==============================] - 2s 8ms/step - loss: 0.0546 - accuracy: 0.9801\n",
      "Epoch 11/30\n",
      "213/213 [==============================] - 2s 8ms/step - loss: 0.0408 - accuracy: 0.9875\n",
      "Epoch 12/30\n",
      "213/213 [==============================] - 2s 8ms/step - loss: 0.0320 - accuracy: 0.9906\n",
      "Epoch 13/30\n",
      "213/213 [==============================] - 2s 8ms/step - loss: 0.0183 - accuracy: 0.9948\n",
      "Epoch 14/30\n",
      "213/213 [==============================] - 2s 8ms/step - loss: 0.0070 - accuracy: 0.9981\n",
      "Epoch 15/30\n",
      "213/213 [==============================] - 2s 8ms/step - loss: 0.0058 - accuracy: 0.9981\n",
      "Epoch 16/30\n",
      "213/213 [==============================] - 2s 8ms/step - loss: 0.0482 - accuracy: 0.9851\n",
      "Epoch 17/30\n",
      "213/213 [==============================] - 2s 8ms/step - loss: 0.0454 - accuracy: 0.9860\n",
      "Epoch 18/30\n",
      "213/213 [==============================] - 2s 8ms/step - loss: 0.0208 - accuracy: 0.9934\n",
      "Epoch 19/30\n",
      "213/213 [==============================] - 2s 8ms/step - loss: 0.0181 - accuracy: 0.9934\n",
      "Epoch 20/30\n",
      "213/213 [==============================] - 2s 8ms/step - loss: 0.0240 - accuracy: 0.9923\n",
      "Epoch 21/30\n",
      "213/213 [==============================] - 2s 8ms/step - loss: 0.0265 - accuracy: 0.9915\n",
      "Epoch 22/30\n",
      "213/213 [==============================] - 2s 8ms/step - loss: 0.0138 - accuracy: 0.9951\n",
      "Epoch 23/30\n",
      "213/213 [==============================] - 2s 8ms/step - loss: 0.0187 - accuracy: 0.9951\n",
      "Epoch 24/30\n",
      "213/213 [==============================] - 2s 8ms/step - loss: 0.0018 - accuracy: 0.9996\n",
      "Epoch 25/30\n",
      "213/213 [==============================] - 2s 8ms/step - loss: 2.6693e-04 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "213/213 [==============================] - 2s 8ms/step - loss: 1.5982e-04 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "213/213 [==============================] - 2s 8ms/step - loss: 1.0918e-04 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "213/213 [==============================] - 2s 8ms/step - loss: 8.6023e-05 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "213/213 [==============================] - 2s 8ms/step - loss: 7.0211e-05 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "213/213 [==============================] - 2s 8ms/step - loss: 5.8738e-05 - accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: saved_model\\assets\n",
      "71/71 - 1s - loss: 1.3232 - accuracy: 0.8754 - 688ms/epoch - 10ms/step\n",
      "0.8754416704177856\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nlabel 5\\n[1, 0, 0, 0, 0]\\n[0, 1, 0, 0, 0]\\n[0, 0, 1, 0, 0]\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation set\n",
    "\n",
    "num_of_data_by_class = {\n",
    "    'A' : {'Light': 67, 'Sedan': 1235, 'SUV': 667, 'Truck': 244, 'Van': 50},\n",
    "    'B' : {'Light': 66, 'Sedan': 1235, 'SUV': 667, 'Truck': 245, 'Van': 50},\n",
    "    'C' : {'Light': 66, 'Sedan': 1235, 'SUV': 668, 'Truck': 244, 'Van': 50},\n",
    "    'D' : {'Light': 66, 'Sedan': 1235, 'SUV': 668, 'Truck': 244, 'Van': 51}\n",
    "}\n",
    "\n",
    "data_fname_by_class = {\n",
    "    'A' : {'Light':{'image':  [], 'label': ['Light'] * num_of_data_by_class['A']['Light']},\n",
    "          'Sedan': {'image':  [], 'label': ['Sedan'] * num_of_data_by_class['A']['Sedan']},\n",
    "          'SUV':   {'image':  [], 'label': ['SUV']   * num_of_data_by_class['A']['SUV']},\n",
    "          'Truck': {'image':  [], 'label': ['Truck'] * num_of_data_by_class['A']['Truck']},\n",
    "          'Van':   {'image':  [], 'label': ['Van']   * num_of_data_by_class['A']['Van']}},\n",
    "\n",
    "    'B' : {'Light':{'image':  [], 'label': ['Light'] * num_of_data_by_class['B']['Light']},\n",
    "          'Sedan': {'image':  [], 'label': ['Sedan'] * num_of_data_by_class['B']['Sedan']},\n",
    "          'SUV':   {'image':  [], 'label': ['SUV']   * num_of_data_by_class['B']['SUV']},\n",
    "          'Truck': {'image':  [], 'label': ['Truck'] * num_of_data_by_class['B']['Truck']},\n",
    "          'Van':   {'image':  [], 'label': ['Van']   * num_of_data_by_class['B']['Van']}},\n",
    "\n",
    "    'C' : {'Light':{'image':  [], 'label': ['Light'] * num_of_data_by_class['C']['Light']},\n",
    "          'Sedan': {'image':  [], 'label': ['Sedan'] * num_of_data_by_class['C']['Sedan']},\n",
    "          'SUV':   {'image':  [], 'label': ['SUV']   * num_of_data_by_class['C']['SUV']},\n",
    "          'Truck': {'image':  [], 'label': ['Truck'] * num_of_data_by_class['C']['Truck']},\n",
    "          'Van':   {'image':  [], 'label': ['Van']   * num_of_data_by_class['C']['Van']}},\n",
    "\n",
    "    'D' : {'Light':{'image':  [], 'label': ['Light'] * num_of_data_by_class['D']['Light']},\n",
    "          'Sedan': {'image':  [], 'label': ['Sedan'] * num_of_data_by_class['D']['Sedan']},\n",
    "          'SUV':   {'image':  [], 'label': ['SUV']   * num_of_data_by_class['D']['SUV']},\n",
    "          'Truck': {'image':  [], 'label': ['Truck'] * num_of_data_by_class['D']['Truck']},\n",
    "          'Van':   {'image':  [], 'label': ['Van']   * num_of_data_by_class['D']['Van']}},\n",
    "}\n",
    "\n",
    "# target_label_list = ['Light', 'Sedan', 'SUV', 'Truck', 'Van']\n",
    "# class_list = ['A', 'B', 'C', 'D']\n",
    "\n",
    "\n",
    "trainset = dataset_shuffle(trainset)\n",
    "for label in label_list: # label_list = ['Light', 'Sedan', 'SUV', 'Truck', 'Van']\n",
    "    dataset = data_by_label(trainset, label)\n",
    "    \n",
    "    j = 0\n",
    "    total = 0\n",
    "    \n",
    "    \n",
    "    for d in range(1, len(dataset['images'])+1):\n",
    "        if j == len(class_list): break\n",
    "            \n",
    "        cls = class_list[j]\n",
    "        data_fname_by_class[cls][label]['image'].append(dataset['images'][d-1])\n",
    "        \n",
    "        \n",
    "        if d - total == num_of_data_by_class[cls][label]:    \n",
    "            j += 1\n",
    "            total += num_of_data_by_class[cls][label]\n",
    "\n",
    "\n",
    "#print(data_fname_by_class['A']['Van'])\n",
    "train_images, train_labels, valid_images, valid_labels  = split_dataset(data_fname_by_class)\n",
    "print(train_images.shape)\n",
    "print(valid_images.shape)\n",
    "\n",
    "train_labels = one_hot_encoding(train_labels)\n",
    "valid_labels = one_hot_encoding(valid_labels)\n",
    "print(train_labels.shape)\n",
    "print(valid_labels.shape)\n",
    "\n",
    "CNN(train_images, train_labels, valid_images, valid_labels)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "dataset (Light)\n",
    "\n",
    "A      B       C       D\n",
    "67     66      66      66\n",
    "   total: 67   t: 133  t: 199  \n",
    "\n",
    "d: 1 ~ 9053 (image 개수만큼 증가하는 값)\n",
    "d: 67 A -> B\n",
    "d: 67 + 66 B -> C\n",
    "d: 67 + 66 + 66 C -> D\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "label 5\n",
    "[1, 0, 0, 0, 0]\n",
    "[0, 1, 0, 0, 0]\n",
    "[0, 0, 1, 0, 0]\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5e745b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test데이터는 레이블이 필요한가...?\n",
    "# test데이터는 그저 이미지를 돌리고 분류를 하는 작업아닌가?\n",
    "\n",
    "testset = dataset_shuffle(testset)['images']\n",
    "cnt = 0\n",
    "for test in testset:\n",
    "    cnt += 1\n",
    "    img = Image.open(f, 'r')\n",
    "    img = img.resize((64, 64))\n",
    "    img = np.array(img) / 255.0\n",
    "    # (64, 64, 3)\n",
    "\n",
    "    image = np.expand_dims(img, axis=0) # (1, 64, 64, 3)\n",
    "\n",
    "\n",
    "    if cnt == 1:\n",
    "        images = image\n",
    "    else:\n",
    "        images = np.append(images, image, axis=0) # (2, 64, 64, 3)\n",
    "        \n",
    "testset_images_array = images\n",
    "print(testset_images_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "336b3b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set, test부분 파일을 읽기, 파일 append;\n",
    "def predict():\n",
    "    model = load_model(MODEL_PATH)\n",
    "    labels = model.predict() # args: test image, # returns: predicted results (labels (one hot encoding))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8136c002",
   "metadata": {},
   "source": [
    "# tensorboard load from log file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7b2fb75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-2fc60c4c5b36f65e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-2fc60c4c5b36f65e\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6185;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir log --host localhost --port=6185"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cac8a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d590c628",
   "metadata": {},
   "source": [
    "# you don't need to run from now on\n",
    "- you can use this code for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "819f72db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_from_excel(datatype):\n",
    "    df = pd.read_excel(EXCEL_PATH + os.sep + datatype +'.xlsx')\n",
    "    print(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4053f2da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0                                             images labels\n",
      "0              0    Resize\\data\\Train\\Day\\Light\\Easy\\UjN9UMOZ_4.jpg  Light\n",
      "1              1    Resize\\data\\Train\\Day\\Light\\Easy\\GnMFtM81_1.jpg  Light\n",
      "2              2    Resize\\data\\Train\\Day\\Light\\Easy\\WlB1bkMI_0.jpg  Light\n",
      "3              3    Resize\\data\\Train\\Day\\Light\\Easy\\CDtud9Tu_3.jpg  Light\n",
      "4              4    Resize\\data\\Train\\Day\\Light\\Easy\\yqs8RTjN_1.jpg  Light\n",
      "...          ...                                                ...    ...\n",
      "9048        9048  Resize\\data\\Train\\Day\\Van\\Moderate\\6YtqZ9GW_4.jpg    Van\n",
      "9049        9049  Resize\\data\\Train\\Day\\Van\\Moderate\\HOcYYNrl_2.jpg    Van\n",
      "9050        9050  Resize\\data\\Train\\Day\\Van\\Moderate\\yPBpKGmx_3.jpg    Van\n",
      "9051        9051  Resize\\data\\Train\\Day\\Van\\Moderate\\bQ5GQoaA_4.jpg    Van\n",
      "9052        9052  Resize\\data\\Train\\Day\\Van\\Moderate\\EHMH9e2o_3.jpg    Van\n",
      "\n",
      "[9053 rows x 3 columns]\n",
      "      Unnamed: 0                                          images labels\n",
      "0              0    Resize\\data\\Test\\Day\\Light\\Easy\\001554_1.jpg  Light\n",
      "1              1    Resize\\data\\Test\\Day\\Light\\Easy\\001153_0.jpg  Light\n",
      "2              2    Resize\\data\\Test\\Day\\Light\\Easy\\001168_0.jpg  Light\n",
      "3              3    Resize\\data\\Test\\Day\\Light\\Easy\\002809_4.jpg  Light\n",
      "4              4    Resize\\data\\Test\\Day\\Light\\Easy\\002714_0.jpg  Light\n",
      "...          ...                                             ...    ...\n",
      "4385        4385  Resize\\data\\Test\\Day\\Van\\Moderate\\002803_3.jpg    Van\n",
      "4386        4386  Resize\\data\\Test\\Day\\Van\\Moderate\\002105_0.jpg    Van\n",
      "4387        4387  Resize\\data\\Test\\Day\\Van\\Moderate\\002906_0.jpg    Van\n",
      "4388        4388  Resize\\data\\Test\\Day\\Van\\Moderate\\002303_2.jpg    Van\n",
      "4389        4389  Resize\\data\\Test\\Day\\Van\\Moderate\\002444_2.jpg    Van\n",
      "\n",
      "[4390 rows x 3 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>images</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Resize\\data\\Test\\Day\\Light\\Easy\\001554_1.jpg</td>\n",
       "      <td>Light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Resize\\data\\Test\\Day\\Light\\Easy\\001153_0.jpg</td>\n",
       "      <td>Light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Resize\\data\\Test\\Day\\Light\\Easy\\001168_0.jpg</td>\n",
       "      <td>Light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Resize\\data\\Test\\Day\\Light\\Easy\\002809_4.jpg</td>\n",
       "      <td>Light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Resize\\data\\Test\\Day\\Light\\Easy\\002714_0.jpg</td>\n",
       "      <td>Light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4385</th>\n",
       "      <td>4385</td>\n",
       "      <td>Resize\\data\\Test\\Day\\Van\\Moderate\\002803_3.jpg</td>\n",
       "      <td>Van</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4386</th>\n",
       "      <td>4386</td>\n",
       "      <td>Resize\\data\\Test\\Day\\Van\\Moderate\\002105_0.jpg</td>\n",
       "      <td>Van</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4387</th>\n",
       "      <td>4387</td>\n",
       "      <td>Resize\\data\\Test\\Day\\Van\\Moderate\\002906_0.jpg</td>\n",
       "      <td>Van</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4388</th>\n",
       "      <td>4388</td>\n",
       "      <td>Resize\\data\\Test\\Day\\Van\\Moderate\\002303_2.jpg</td>\n",
       "      <td>Van</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4389</th>\n",
       "      <td>4389</td>\n",
       "      <td>Resize\\data\\Test\\Day\\Van\\Moderate\\002444_2.jpg</td>\n",
       "      <td>Van</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4390 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                          images labels\n",
       "0              0    Resize\\data\\Test\\Day\\Light\\Easy\\001554_1.jpg  Light\n",
       "1              1    Resize\\data\\Test\\Day\\Light\\Easy\\001153_0.jpg  Light\n",
       "2              2    Resize\\data\\Test\\Day\\Light\\Easy\\001168_0.jpg  Light\n",
       "3              3    Resize\\data\\Test\\Day\\Light\\Easy\\002809_4.jpg  Light\n",
       "4              4    Resize\\data\\Test\\Day\\Light\\Easy\\002714_0.jpg  Light\n",
       "...          ...                                             ...    ...\n",
       "4385        4385  Resize\\data\\Test\\Day\\Van\\Moderate\\002803_3.jpg    Van\n",
       "4386        4386  Resize\\data\\Test\\Day\\Van\\Moderate\\002105_0.jpg    Van\n",
       "4387        4387  Resize\\data\\Test\\Day\\Van\\Moderate\\002906_0.jpg    Van\n",
       "4388        4388  Resize\\data\\Test\\Day\\Van\\Moderate\\002303_2.jpg    Van\n",
       "4389        4389  Resize\\data\\Test\\Day\\Van\\Moderate\\002444_2.jpg    Van\n",
       "\n",
       "[4390 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_from_excel('train')\n",
    "data_from_excel('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69289ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_resize_and_save(files): # 이미 설정된 경로에 파일이 save되니 return값 불필요?\n",
    "    for f in files:\n",
    "        img = Image.open(f, 'r')\n",
    "        resized_img = img.resize((64, 64))\n",
    "\n",
    "        dir_name, file_name = os.path.split(RESIZE_PATH + os.sep + f) \n",
    "        # 파일부분과 폴더부분을 나눔\n",
    "        \n",
    "        os.makedirs(dir_name, exist_ok=True)\n",
    "        resized_img.save(RESIZE_PATH + os.sep + f) \n",
    "        # full_name으로 파일 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58ab8c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_resize_and_save(trainset['images'])\n",
    "image_resize_and_save(testset['images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72357fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
